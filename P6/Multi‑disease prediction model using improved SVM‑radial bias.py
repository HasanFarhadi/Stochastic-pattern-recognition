# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PrR9hpfuxLt2ge-HHu2TdMsKBPjf-yC8
"""

from scipy.io import arff
import pandas as pd
import numpy as np
from sklearn import datasets
import copy
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
import matplotlib.pyplot as plt

#accuracy
def Accuracy(y, test_data, theta):
    yhat = np.sign(np.dot(test_data, theta)).astype(int)
    tp = 0
    tn = 0
    fp = 0
    fn = 0
    m = len(y)
    for i in range(m):
        if yhat[i] == y[i]:
            if yhat[i] == 1:
                tp += 1
            else:
                tn += 1
        else:
            if yhat[i] == 1:
                fp += 1
            else:
                fn += 1
    accuracy = 100*(tp + tn) / m
    misclassification = 100*(fp + fn) / m
    recall = 100*tp / (tp + fn)
    precision = 100*tp / (tp + fp)

    print(f"Accuracy : {accuracy}%")
    print(f"Misclassification Rate: {misclassification}%")
    print(f"Recall : {recall}%")
    print(f"Precision : {precision}%")
    return accuracy

#rbf function
def RBF(data1, data2, gamma):
    distance = np.power(np.linalg.norm(data1 - data2), 2)
    rbf = np.exp(-distance / (2 * np.power(gamma, 2)))
    return rbf

#rbf kernel
def Kernel(input, landmark, gamma):
    sample_count = np.shape(input)[0]
    landmark_count = np.shape(landmark)[0]
    kernel = np.zeros((sample_count, landmark_count))
    for i in range(sample_count):
        for j in range(landmark_count):
            kernel[i, j] = RBF(input[i], landmark[j], gamma)

    return kernel

#svm model training
def GDescent(learning_rate, iterations, features, labels):
    theta = np.ones(np.shape(features)[1]).reshape(-1, 1)
    for iteration in range(1, iterations):
        yhat = np.dot(features, theta)
        for index, data in enumerate(features):
            if (labels[index] * yhat[index]) < 1:
                theta = theta + learning_rate * (( features[index] * labels[index] ).reshape(-1, 1) + ((-2/iteration) * theta))
            else:
                theta = theta + learning_rate * ( (-2/iteration) * theta)
    return theta

#load CKD
def Load_CKD(path):
    data = pd.read_csv(path)
    data["classification"].replace({"ckd": 1, "notckd": 0}, inplace= True)
    data["rbc"].replace({"normal": 0, "abnormal": 1}, inplace= True)
    data["pc"].replace({"normal": 0, "abnormal": 1}, inplace = True)
    data["pcc"].replace({"notpresent": 0, "present": 1}, inplace = True)
    data["ba"].replace({"notpresent": 0, "present": 1}, inplace = True)
    data["htn"].replace({"no": 0, "yes": 1}, inplace = True)
    data["dm"].replace({"no": 0, "yes": 1}, inplace = True)
    data["cad"].replace({"no": 0, "yes": 1}, inplace = True)
    data["appet"].replace({"good": 0, "poor": 1}, inplace = True)
    data["pe"].replace({"no": 0, "yes": 1}, inplace = True)
    data["ane"].replace({"no": 0, "yes": 1}, inplace = True)
    #data.interpolate(method='linear', inplace= True)
    data = data.dropna(axis = 0)
    data = np.array(data.iloc[:, 1:-1])
    data = MinMaxScaler().fit_transform(data)
    label = data[:, -1]
    input = data[:, 0:-1]
    return input, label

#load HeartDisease
def Load_HeartDisease(path):
    data = pd.read_csv(path,na_values='?', header= None)
    data = data.dropna(axis = 0)
    data = data.loc[data[13].isin([0, 1])]
    data = MinMaxScaler().fit_transform(data)
    label = data[:, -1]
    input = data[:, 0:-1]
    return input, label

input, label = Load_CKD('/content/drive/MyDrive/Depo/UCI ML Repo/Chronic Kidney Disease/kidney_disease.csv')

#input, label = Load_HeartDisease('/content/drive/MyDrive/Depo/UCI ML Repo/Heart Disease/processed.cleveland (1).data')

#feature selection
chi2_selection = SelectKBest(chi2, k=5)
input = chi2_selection.fit_transform(input, label)

#preparing the data for training and testing the model
input_train, input_test, label_train, label_test = train_test_split(input, label, test_size= 0.2, stratify= label, random_state=7)
input_train = np.append(np.ones((len(input_train), 1)), input_train, axis=1)
label_train = np.reshape(label_train, (-1, 1))
label_train = ((label_train - 0.5) * 2).astype(int)
learning_rate = 0.1
iterations = 1000

input_test = np.append(np.ones((len(input_test), 1)), input_test, axis=1)
label_test = np.reshape(label_test, (-1, 1))
label_test = ((label_test - 0.5) * 2).astype(int)

kernel_input_train = Kernel(input_train, input_train, 0.1)
kernel_input_test = Kernel(input_test,input_train, gamma = 0.1)

theta = GDescent(learning_rate, iterations, kernel_input_train, label_train)
accuracy = Accuracy(label_test, kernel_input_test, theta)